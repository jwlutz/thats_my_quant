# ADR-0001: Local-First Architecture with LLM for Narrative Only

## Status
**ACCEPTED** - 2024-12-19

## Context

We need to build a stock market research workbench that generates comprehensive research reports combining quantitative metrics with qualitative narrative. Key requirements include:

- Reliable, reproducible calculations
- Integration of price data (yfinance) and institutional holdings (13F)
- Natural language summaries and risk descriptions
- Full data traceability
- No cloud dependencies for MVP
- User control over all data

The main architectural decision is how to structure the system and how to use LLMs without compromising data integrity.

## Decision Drivers

1. **Accuracy**: Financial calculations must be 100% accurate
2. **Reproducibility**: Same inputs must produce same outputs
3. **Traceability**: Every number must trace to source
4. **Simplicity**: MVP should be simple to run and understand
5. **Privacy**: User data stays local
6. **Cost**: Minimize ongoing operational costs

## Considered Options

### Option 1: Cloud-Based with Full LLM Integration
- **Pros**: 
  - Could leverage GPT-4 for all analysis
  - Scalable infrastructure
  - No local compute requirements
- **Cons**:
  - LLMs hallucinate numbers
  - Ongoing API costs
  - Data privacy concerns
  - Internet dependency
  - Not reproducible

### Option 2: Local-First with LLM Calculations
- **Pros**:
  - Local control
  - No ongoing costs
  - Data privacy
- **Cons**:
  - LLMs still hallucinate
  - Calculations not verifiable
  - Results vary between runs

### Option 3: Local-First with LLM for Narrative Only ✅
- **Pros**:
  - Calculations 100% deterministic
  - LLM adds value through prose
  - Fully reproducible metrics
  - No hallucinated numbers
  - Local control
  - Traceable data
- **Cons**:
  - More code to write
  - Requires Ollama setup
  - Limited to narrative enhancement

### Option 4: Pure Code, No LLM
- **Pros**:
  - Simplest architecture
  - Fully deterministic
  - No external dependencies
- **Cons**:
  - Reports lack narrative flow
  - Missing qualitative insights
  - Less engaging output

## Decision

**We will use Option 3: Local-First with LLM for Narrative Only**

### Architecture

```
┌─────────────────┐
│   CLI Entry     │
└────────┬────────┘
         │
    ┌────▼────┐
    │   Run   │────► SQLite DB
    │ Manager │      (runs, status)
    └────┬────┘
         │
    ┌────▼────┐
    │ Ingest  │────► yfinance API
    │ Layer   │────► SEC EDGAR
    └────┬────┘
         │
    ┌────▼────┐
    │  Data   │────► SQLite DB
    │  Store  │      (prices, holdings)
    └────┬────┘
         │
    ┌────▼────┐
    │Analysis │────► Pure Python
    │ Engine  │      (calculations)
    └────┬────┘
         │
    ┌────▼────┐
    │ Report  │────► Ollama API
    │Generator│      (narrative only)
    └────┬────┘
         │
    ┌────▼────┐
    │Markdown │
    │  Output │
    └─────────┘
```

### Implementation Rules

1. **All calculations in Python code**
   - Returns, volatility, drawdown
   - Holdings concentration
   - Data coverage statistics

2. **LLM receives structured data, returns prose**
   ```python
   input = {
       "metrics": {...},  # Pre-calculated
       "constraints": {
           "max_words": 200,
           "tone": "professional"
       }
   }
   ```

3. **LLM output validation**
   - Check word count
   - Scan for hallucinated numbers
   - Verify no recommendations
   - Fallback to template if invalid

4. **Data storage layers**
   - SQLite for structured data
   - JSON for cache
   - Markdown for reports
   - Parquet for time series

## Consequences

### Positive
- **100% accurate calculations**: No hallucination risk
- **Full reproducibility**: Metrics always consistent
- **Complete traceability**: Source for every number
- **Local control**: User owns all data
- **Low cost**: No ongoing API fees
- **Privacy**: No data leaves machine
- **Testable**: Can unit test all calculations

### Negative
- **More implementation work**: Must code all metrics
- **Ollama requirement**: Users need local LLM
- **Limited narrative**: LLM can't provide deep analysis
- **No predictive capabilities**: Backward-looking only

### Neutral
- **Performance**: Local compute requirements
- **Maintenance**: Need to update calculations
- **Flexibility**: Adding metrics requires code

## Risk Mitigation

| Risk | Mitigation |
|------|------------|
| Ollama unavailable | Fallback to template-only reports |
| LLM hallucinates | Strict validation, number extraction |
| Calculation errors | Comprehensive unit tests |
| Data unavailable | Cache layer, multiple sources |

## Validation

We will validate this decision through:
1. Golden ticker tests (AAPL, MSFT, SPY)
2. Calculation accuracy tests
3. LLM output validation tests
4. User acceptance testing
5. Performance benchmarks

## Notes

- This decision can be revisited after MVP
- Cloud features could be added as optional
- More sophisticated LLM integration possible later
- Focus on getting working system first

## References

- [yfinance Documentation](https://github.com/ranaroussi/yfinance)
- [SEC EDGAR API](https://www.sec.gov/edgar/sec-api-documentation)
- [Ollama Documentation](https://ollama.ai/docs)
- [SQLite Best Practices](https://www.sqlite.org/bestpractice.html)

---

**Decided by**: Architecture Team  
**Date**: 2024-12-19  
**Review Date**: After MVP completion
